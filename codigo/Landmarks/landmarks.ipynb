{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Drowsiness _detection.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"VdseHb_eSkeU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654091869430,"user_tz":-120,"elapsed":14603,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}},"outputId":"f3420fb4-c82d-4b8e-ba54-836b55990a0d"},"source":["!pip install --upgrade imutils \n","!pip install pygobject\n","!pip install playsound"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pygobject in /usr/lib/python3/dist-packages (3.26.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: playsound in /usr/local/lib/python3.7/dist-packages (1.3.0)\n"]}]},{"cell_type":"code","metadata":{"id":"c26WpXAK0_Sa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654091872451,"user_tz":-120,"elapsed":3026,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}},"outputId":"4fd433f3-83ec-4efb-b788-76dc3cbbefab"},"source":["!wget https://github.com/Practical-CV/Facial-Landmarks-Detection-with-DLIB/blob/master/facial_landmarks.py\n","!wget -nd https://github.com/JeffTrain/selfie/raw/master/shape_predictor_68_face_landmarks.dat"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-06-01 13:57:49--  https://github.com/Practical-CV/Facial-Landmarks-Detection-with-DLIB/blob/master/facial_landmarks.py\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: ‘facial_landmarks.py.1’\n","\n","facial_landmarks.py     [ <=>                ] 154.40K   872KB/s    in 0.2s    \n","\n","2022-06-01 13:57:50 (872 KB/s) - ‘facial_landmarks.py.1’ saved [158109]\n","\n","--2022-06-01 13:57:50--  https://github.com/JeffTrain/selfie/raw/master/shape_predictor_68_face_landmarks.dat\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/JeffTrain/selfie/master/shape_predictor_68_face_landmarks.dat [following]\n","--2022-06-01 13:57:50--  https://raw.githubusercontent.com/JeffTrain/selfie/master/shape_predictor_68_face_landmarks.dat\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 99693937 (95M) [application/octet-stream]\n","Saving to: ‘shape_predictor_68_face_landmarks.dat.1’\n","\n","shape_predictor_68_ 100%[===================>]  95.08M   234MB/s    in 0.4s    \n","\n","2022-06-01 13:57:52 (234 MB/s) - ‘shape_predictor_68_face_landmarks.dat.1’ saved [99693937/99693937]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"x7V8BNr6exOG","executionInfo":{"status":"ok","timestamp":1654091872452,"user_tz":-120,"elapsed":8,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}}},"source":["# import the necessary packages\n","from scipy.spatial import distance as dist\n","from imutils.video import VideoStream\n","from imutils import face_utils\n","from threading import Thread\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import numpy as np\n","import playsound\n","import argparse\n","import imutils\n","import time\n","import dlib\n","import cv2\n","import io\n","import html\n","import PIL\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"09b_0FAnUa9y","executionInfo":{"status":"ok","timestamp":1654091872452,"user_tz":-120,"elapsed":7,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}}},"source":["# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"b3BpMQ8Ue8kb","executionInfo":{"status":"ok","timestamp":1654091872452,"user_tz":-120,"elapsed":7,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}}},"source":["def sound_alarm(path):\n","\t# play an alarm sound\n","\tplaysound.playsound(path)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"0nvxlI9xjIjo","executionInfo":{"status":"ok","timestamp":1654091872453,"user_tz":-120,"elapsed":8,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}}},"source":["def eye_aspect_ratio(eye):\n","\t# compute the euclidean distances between the two sets of\n","\t# vertical eye landmarks (x, y)-coordinates\n","\tA = dist.euclidean(eye[1], eye[5])\n","\tB = dist.euclidean(eye[2], eye[4])\n","\t# compute the euclidean distance between the horizontal\n","\t# eye landmark (x, y)-coordinates\n","\tC = dist.euclidean(eye[0], eye[3])\n","\t# compute the eye aspect ratio\n","\tear = (A + B) / (2.0 * C)\n","\t# return the eye aspect ratio\n","\treturn ear"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"jVL1rn5pIl23","executionInfo":{"status":"ok","timestamp":1654091872453,"user_tz":-120,"elapsed":8,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}}},"source":["# construct the argument parse and parse the arguments\n","ap = argparse.ArgumentParser()\n","ap.add_argument(\"-p\", \"--shape-predictor\", required=True,\n","\thelp=\"path to facial landmark predictor\")\n","ap.add_argument(\"-a\", \"--alarm\", type=str, default=\"\",\n","\thelp=\"path alarm .WAV file\")\n","ap.add_argument(\"-w\", \"--webcam\", type=int, default=0,\n","\thelp=\"index of webcam on system\")\n","args = vars(ap.parse_args(\"-p shape_predictor\".split()))\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"RK9V-DT7mmtp","executionInfo":{"status":"ok","timestamp":1654091872453,"user_tz":-120,"elapsed":7,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}}},"source":["# define two constants, one for the eye aspect ratio to indicate\n","# blink and then a second constant for the number of consecutive\n","# frames the eye must be below the threshold for to set off the\n","# alarm\n","EYE_AR_THRESH = 0.3\n","EYE_AR_CONSEC_FRAMES = 48\n","# initialize the frame counter as well as a boolean used to\n","# indicate if the alarm is going off\n","COUNTER = 0\n","ALARM_ON = False"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"3000Gk7MHnpY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654091874274,"user_tz":-120,"elapsed":1828,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}},"outputId":"36cf1d44-7216-44a3-cd5d-6a3cb4f3f197"},"source":["# initialize dlib's face detector (HOG-based) and then create\n","# the facial landmark predictor\n","print(\"[INFO] loading facial landmark predictor...\")\n","detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor(\"/content/shape_predictor_68_face_landmarks.dat\")"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] loading facial landmark predictor...\n"]}]},{"cell_type":"code","metadata":{"id":"DZG-YbdBJFKe","executionInfo":{"status":"ok","timestamp":1654091874274,"user_tz":-120,"elapsed":6,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}}},"source":["# grab the indexes of the facial landmarks for the left and\n","# right eye, respectively\n","(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n","(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghUlAJzKSjFT","executionInfo":{"status":"ok","timestamp":1654091874275,"user_tz":-120,"elapsed":6,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}}},"source":["# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"1nkSnkbkk4cC","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1654091987908,"user_tz":-120,"elapsed":108627,"user":{"displayName":"Diego Novoa Paradela","userId":"02241273766743840096"}},"outputId":"f4b3ea92-82de-43db-ce30-8dc17310bb73"},"source":["# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","\n","bbox = ''\n","count = 0 \n","ear = 0\n","\n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    frame = js_to_image(js_reply[\"img\"])\n","\n","    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","\n","    # grayscale image for face detection\n","    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n","\n","    # get face region coordinates\n","    rects = detector(gray, 0)\n","    # get face for overlay\n","    for rect in rects:\n","        shape = predictor(gray, rect)\n","        shape = face_utils.shape_to_np(shape)\n","\n","        leftEye = shape[lStart:lEnd]\n","        rightEye = shape[rStart:rEnd]\n","        leftEAR = eye_aspect_ratio(leftEye)\n","        rightEAR = eye_aspect_ratio(rightEye)\n","\n","        ear = (leftEAR + rightEAR) / 2.0\n","\n","        leftEyeHull = cv2.convexHull(leftEye)\n","        rightEyeHull = cv2.convexHull(rightEye)\n","      \n","        bbox_array = cv2.drawContours(bbox_array, [leftEyeHull], -1, (0, 255, 0), 1)\n","        bbox_array = cv2.drawContours(bbox_array, [rightEyeHull], -1, (0, 255, 0), 1)\n","\n","    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","    # convert overlay into bytes\n","    bbox_bytes = bbox_to_bytes(bbox_array)\n","    # next frame gets new overlay\n","    bbox = bbox_bytes"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    "]},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Id4rb7lVCptK"},"outputs":[],"source":["# check to see if the eye aspect ratio is below the blink\n","\t\t# threshold, and if so, increment the blink frame counter\n","if ear < EYE_AR_THRESH:\n","\t\t\tCOUNTER += 1\n","\t\t\t# if the eyes were closed for a sufficient number of\n","\t\t\t# then sound the alarm\n","\t\t\tif COUNTER >= EYE_AR_CONSEC_FRAMES:\n","\t\t\t\t# if the alarm is not on, turn it on\n","\t\t\t\tif not ALARM_ON:\n","\t\t\t\t\tALARM_ON = True\n","\t\t\t\t\t# check to see if an alarm file was supplied,\n","\t\t\t\t\t# and if so, start a thread to have the alarm\n","\t\t\t\t\t# sound played in the background\n","\t\t\t\t\tif args[\"alarm\"] != \"\":\n","\t\t\t\t\t\tt = Thread(target=sound_alarm,\n","\t\t\t\t\t\t\targs=(args[\"alarm\"],))\n","\t\t\t\t\t\tt.deamon = True\n","\t\t\t\t\t\tt.start()\n","\t\t\t\t# draw an alarm on the frame\n","\t\t\t\tcv2.putText(frame, \"DROWSINESS ALERT!\", (10, 30),\n","\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n","\t\t# otherwise, the eye aspect ratio is not below the blink\n","\t\t# threshold, so reset the counter and alarm\n","else:\n","\t\t\tCOUNTER = 0\n","\t\t\tALARM_ON = False\n","\n","from google.colab.patches import cv2_imshow\n","# draw the computed eye aspect ratio on the frame to help\n","\t\t# with debugging and setting the correct eye aspect ratio\n","\t\t# thresholds and frame counters\n","cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30),\n","cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)"]}]}